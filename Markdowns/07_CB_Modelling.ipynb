{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Content Based Modelling\n",
    "\n",
    "### Team A -  Sergi Abashidze, Camila Barbagallo, Paula García, Rocío González Lantero\n",
    "\n",
    "#### 17/11/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from xgboost import XGBRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"OldMovies_complete.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_ratings</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>...</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci.Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Duration</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100029</td>\n",
       "      <td>9399</td>\n",
       "      <td>599.0</td>\n",
       "      <td>26696</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>108</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100029</td>\n",
       "      <td>9399</td>\n",
       "      <td>599.0</td>\n",
       "      <td>26696</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>108</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100029</td>\n",
       "      <td>9399</td>\n",
       "      <td>599.0</td>\n",
       "      <td>26696</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>108</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100029</td>\n",
       "      <td>9399</td>\n",
       "      <td>599.0</td>\n",
       "      <td>26696</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>108</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100029</td>\n",
       "      <td>9399</td>\n",
       "      <td>599.0</td>\n",
       "      <td>26696</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2017-06-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>108</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdbId  tmdbId  userId  movieId  rating date_ratings  Action  Adventure  \\\n",
       "0  100029    9399   599.0    26696     0.5   2017-06-26       1          0   \n",
       "1  100029    9399   599.0    26696     0.5   2017-06-26       1          0   \n",
       "2  100029    9399   599.0    26696     0.5   2017-06-26       1          0   \n",
       "3  100029    9399   599.0    26696     0.5   2017-06-26       1          0   \n",
       "4  100029    9399   599.0    26696     0.5   2017-06-26       1          0   \n",
       "\n",
       "   Animation  Children  ...  Musical  Mystery  Romance  Sci.Fi  Thriller  War  \\\n",
       "0          0         0  ...        0        0        0       0         0    0   \n",
       "1          0         0  ...        0        0        0       0         0    0   \n",
       "2          0         0  ...        0        0        0       0         0    0   \n",
       "3          0         0  ...        0        0        0       0         0    0   \n",
       "4          0         0  ...        0        0        0       0         0    0   \n",
       "\n",
       "   Western  ReleaseDate  Duration  IMDB_Rating  \n",
       "0        0         1990       108          6.2  \n",
       "1        0         1990       108          6.2  \n",
       "2        0         1990       108          6.2  \n",
       "3        0         1990       108          6.2  \n",
       "4        0         1990       108          6.2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation\n",
    "\n",
    "## 1.1 Data cleaning\n",
    "\n",
    "### 1.1.1 Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imdbId          0\n",
       "tmdbId          0\n",
       "userId          0\n",
       "movieId         0\n",
       "rating          0\n",
       "date_ratings    0\n",
       "Action          0\n",
       "Adventure       0\n",
       "Animation       0\n",
       "Children        0\n",
       "Comedy          0\n",
       "Crime           0\n",
       "Documentary     0\n",
       "Drama           0\n",
       "Fantasy         0\n",
       "Film.Noir       0\n",
       "Horror          0\n",
       "IMAX            0\n",
       "Musical         0\n",
       "Mystery         0\n",
       "Romance         0\n",
       "Sci.Fi          0\n",
       "Thriller        0\n",
       "War             0\n",
       "Western         0\n",
       "ReleaseDate     0\n",
       "Duration        0\n",
       "IMDB_Rating     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9954016"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop_duplicates(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Feature engineering\n",
    "\n",
    "**Ids**\n",
    "\n",
    "If we wanted to use the ids, we would need to preprocess them. However, we have enough information for each observation and little computing resources, so we will leave this for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\pandas\\core\\frame.py:4170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df.drop(['imdbId','tmdbId','movieId','userId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__date_ratings__\n",
    "\n",
    "To take the date into account within the models, we will extract the days since the rating and save the date as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\pandas\\core\\generic.py:5168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "C:\\Users\\Usuario\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Usuario\\Anaconda3\\envs\\MachineLearning\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# convert to date format: year-month-day\n",
    "df.date_ratings = pd.to_datetime(df.date_ratings, format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "#new column with todays date\n",
    "df['today'] = '2020-11-17'\n",
    "\n",
    "#convert new column to date\n",
    "df.today = pd.to_datetime(df.today, format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "#creating a new variable that describes for how many days a host has been a host\n",
    "df['days_since_rating'] = (df['today']-df['date_ratings']).dt.days\n",
    "\n",
    "#dropping today\n",
    "df = df.drop('today', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save date as index\n",
    "df = df.set_index('date_ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReleaseDate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to date format: year-\n",
    "df.ReleaseDate = pd.to_datetime(df.ReleaseDate, format='%Y', errors='coerce')\n",
    "\n",
    "#new column with todays date\n",
    "df['year'] = '2020'\n",
    "\n",
    "#convert new column to date\n",
    "df.year = pd.to_datetime(df.year, format='%Y', errors='coerce')\n",
    "\n",
    "#creating a new variable that describes for how many years the movie has been released\n",
    "df['days_since_release'] = (df['year']-df['ReleaseDate']).dt.days\n",
    "\n",
    "#dropping year and ReleaseDate, as we have already extracted the information they contain\n",
    "df = df.drop(['year','ReleaseDate'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have processed all the variables, the data looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci.Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>Duration</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "      <th>days_since_rating</th>\n",
       "      <th>days_since_release</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_ratings</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-26</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1240</td>\n",
       "      <td>10957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7299</td>\n",
       "      <td>10957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-05-31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5649</td>\n",
       "      <td>10957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5021</td>\n",
       "      <td>10957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1240</td>\n",
       "      <td>10957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              rating  Action  Adventure  Animation  Children  Comedy  Crime  \\\n",
       "date_ratings                                                                  \n",
       "2017-06-26       0.5       1          0          0         0       0      0   \n",
       "2000-11-23       4.0       0          0          0         0       0      0   \n",
       "2005-05-31       1.0       0          0          0         0       1      0   \n",
       "2007-02-18       3.0       0          0          0         0       1      0   \n",
       "2017-06-26       2.0       0          0          0         0       1      0   \n",
       "\n",
       "              Documentary  Drama  Fantasy  ...  Mystery  Romance  Sci.Fi  \\\n",
       "date_ratings                               ...                             \n",
       "2017-06-26              0      0        0  ...        0        0       0   \n",
       "2000-11-23              0      1        0  ...        0        0       0   \n",
       "2005-05-31              0      0        0  ...        0        1       0   \n",
       "2007-02-18              0      0        0  ...        0        1       0   \n",
       "2017-06-26              0      0        0  ...        0        1       0   \n",
       "\n",
       "              Thriller  War  Western  Duration  IMDB_Rating  \\\n",
       "date_ratings                                                  \n",
       "2017-06-26           0    0        0       108          6.2   \n",
       "2000-11-23           0    0        0        97          7.3   \n",
       "2005-05-31           0    0        0        81          4.7   \n",
       "2007-02-18           0    0        0        81          4.7   \n",
       "2017-06-26           0    0        0        81          4.7   \n",
       "\n",
       "              days_since_rating  days_since_release  \n",
       "date_ratings                                         \n",
       "2017-06-26                 1240               10957  \n",
       "2000-11-23                 7299               10957  \n",
       "2005-05-31                 5649               10957  \n",
       "2007-02-18                 5021               10957  \n",
       "2017-06-26                 1240               10957  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_ts(df, test_size= 0.2):\n",
    "    size= int(np.round(len(df)*0.2))\n",
    "    train= df.iloc[:-size]\n",
    "    test= df.iloc[-size:]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['rating']\n",
    "X = df.drop('rating',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 70% of our data for training and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_ts(X, test_size=0.3)\n",
    "y_train, y_test = train_test_ts(y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Normalization\n",
    "\n",
    "To start modelling giving the same importance to all our features we will normalize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scale = MinMaxScaler().fit(X_train)\n",
    "X_train = mm_scale.transform(X_train)\n",
    "X_test = mm_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dimensionality reduction: PCA\n",
    "\n",
    "We have a lot of features and we don't care about why a user prefers one movie to another, dimensionality reduction is recommended to simplify the modelling process and most likely give better results.\n",
    "\n",
    "**Choose number of components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20050677, 0.36945844, 0.47399421, 0.55465005, 0.62182394,\n",
       "       0.68013849, 0.72474107, 0.76734735, 0.80752021, 0.84342491,\n",
       "       0.87553613, 0.90312808, 0.92607845, 0.94340969, 0.95777165,\n",
       "       0.96990309, 0.97886803, 0.98490429, 0.99083805, 0.99372425,\n",
       "       0.9964627 , 0.99843798, 1.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA().fit(X_train)\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the table and graph, we conclude that after approximately the 19th principal component the explained variance doesn't increase significantly. Therefore, we will use 19 principal components. \n",
    "\n",
    "**Save number of components as features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=19).fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_train = pd.DataFrame(data = X_train, \n",
    "                       columns = ['PC1', 'PC2','PC3','PC4','PC5','PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11','PC12'\n",
    "                                  , 'PC13', 'PC14', 'PC15', 'PC16', 'PC17','PC18', 'PC19'])\n",
    "X_test = pca.transform(X_test)\n",
    "X_test = pd.DataFrame(data = X_test, \n",
    "                      columns = ['PC1', 'PC2','PC3','PC4','PC5','PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11','PC12'\n",
    "                                , 'PC13', 'PC14', 'PC15', 'PC16', 'PC17','PC18', 'PC19'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squared Error:  0.9412620050041913\n",
      "Test Root Mean Squared Error:  0.9551073936369556\n"
     ]
    }
   ],
   "source": [
    "mlr = lm.LinearRegression()\n",
    "mlr.fit(X_train, y_train)\n",
    "\n",
    "y_trainpred = mlr.predict(X_train)\n",
    "y_pred = mlr.predict(X_test)\n",
    "\n",
    "print (\"Train Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_train, y_trainpred)))\n",
    "print (\"Test Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squared Error:  0.10778419224119425\n",
      "Test Root Mean Squared Error:  1.5543768312169308\n"
     ]
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "dtr.fit(X_train,y_train)\n",
    "\n",
    "y_trainpred = dtr.predict(X_train)\n",
    "y_pred = dtr.predict(X_test)\n",
    "\n",
    "print (\"Train Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_train, y_trainpred)))\n",
    "print (\"Test Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squared Error:  0.4013595648172423\n",
      "Test Root Mean Squared Error:  1.0109740563244067\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=0)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "y_trainpred = rf.predict(X_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print (\"Train Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_train, y_trainpred)))\n",
    "print (\"Test Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 MLP regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squared Error:  0.9219168374330297\n",
      "Test Root Mean Squared Error:  0.9590273334307909\n"
     ]
    }
   ],
   "source": [
    "nn = MLPRegressor(random_state=0)\n",
    "\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "y_trainpred = nn.predict(X_train)\n",
    "y_pred = nn.predict(X_test)\n",
    "\n",
    "print (\"Train Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_train, y_trainpred)))\n",
    "print (\"Test Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Support vector regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squared Error:  0.9330784196801502\n",
      "Test Root Mean Squared Error:  0.9575314279298017\n"
     ]
    }
   ],
   "source": [
    "svr = SVR()\n",
    "\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "y_trainpred = svr.predict(X_train)\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "print (\"Train Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_train, y_trainpred)))\n",
    "print (\"Test Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squared Error:  0.8614380437815591\n",
      "Test Root Mean Squared Error:  0.9799647626838621\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_trainpred = xgb.predict(X_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "print (\"Train Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_train, y_trainpred)))\n",
    "print (\"Test Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Preliminary results\n",
    "\n",
    "From the models above we have the following results:\n",
    "\n",
    "| Model                 | Train  | Test   | Difference| Behaviour  |\n",
    "|-----------------------|--------|--------|-----------|------------|\n",
    "| **Linear Regression** | 0.9412 | 0.9551 | 0.0139    | Overfitted |\n",
    "| **Decision Tree**     | 0.1078 | 1.5544 | 1.4466    | Overfitted |\n",
    "| **Random Forest**     | 0.4014 | 1.011  | 0.6096    | Overfitted |\n",
    "| <code style=\"background:yellow\">**MLP Regressor**     | 0.9219 | 0.9590 | 0.0371    | Overfitted |\n",
    "| **SVR**               | 0.9331 | 0.9575 | 0.0244    | Overfitted |\n",
    "| <code style=\"background:yellow\">**XGBoost**           | 0.8614 | 0.98   | 0.0546    | Overfitted |\n",
    "\n",
    "We will proceed to fine tune MLP Regressor and XGBoost, as they seem to be the models that best predict the ratings for the movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model fine tuning\n",
    "\n",
    "Once we have the top models, we need to proceed to fine tune them, to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.1 MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (100,),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 200,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': 0,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Parameters currently in use:\\n')\n",
    "nn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "'hidden_layer_sizes': (np.arange(10,30,5), np.arange(10,30,5)),\n",
    "'activation': ['identity','logistic','tanh','relu'],\n",
    "'solver': ['adam','lbfgs','sgd'],\n",
    "'learning_rate': ['invscaling','constant','adaptive']}\n",
    "\n",
    "\n",
    "nn_rs = RandomizedSearchCV(estimator=nn, param_distributions=parameters, scoring='neg_root_mean_squared_error',\n",
    "                            cv=10, verbose=2, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squared Error:  0.9379164195501649\n",
      "Test Root Mean Squared Error:  0.9490516506590705\n"
     ]
    }
   ],
   "source": [
    "nn_rs.fit(X_train, y_train)\n",
    "\n",
    "y_trainpred = nn_rs.predict(X_train)\n",
    "y_pred = nn_rs.predict(X_test)\n",
    "\n",
    "print (\"Train Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_train, y_trainpred)))\n",
    "print (\"Test Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'solver': 'adam', 'learning_rate': 'invscaling', 'hidden_layer_sizes': array([10, 15, 20, 25]), 'activation': 'logistic'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyper Parameters:\\n\",nn_rs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'gamma': 0,\n",
       " 'gpu_id': -1,\n",
       " 'importance_type': 'gain',\n",
       " 'interaction_constraints': '',\n",
       " 'learning_rate': 0.300000012,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': '()',\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': 0,\n",
       " 'num_parallel_tree': 1,\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 1,\n",
       " 'tree_method': 'exact',\n",
       " 'validate_parameters': 1,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Parameters currently in use:\\n')\n",
    "xgb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "'max_depth': np.arange(10,30,5),\n",
    "'min_child_weight': range(10,30),\n",
    "'n_estimators': range(40, 100, 5),\n",
    "'reg_alpha': [0.1,0.3,0.4,0.5],\n",
    "'reg_lambda':[1.3,1.4,1.5,1.6,1.7],\n",
    "'learning_rate': [0.3,0.2,0.25,0.1]}\n",
    "\n",
    "\n",
    "xgb_rs = RandomizedSearchCV(estimator=xgb, param_distributions=parameters, scoring='neg_root_mean_squared_error',\n",
    "                            cv=10, verbose=2, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 20.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squared Error:  0.8580082943697498\n",
      "Test Root Mean Squared Error:  0.9741318111808973\n"
     ]
    }
   ],
   "source": [
    "xgb_rs.fit(X_train, y_train)\n",
    "\n",
    "y_trainpred = xgb_rs.predict(X_train)\n",
    "y_pred = xgb_rs.predict(X_test)\n",
    "\n",
    "print (\"Train Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_train, y_trainpred)))\n",
    "print (\"Test Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:\n",
      " {'reg_lambda': 1.6, 'reg_alpha': 0.1, 'n_estimators': 45, 'min_child_weight': 21, 'max_depth': 10, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyper Parameters:\\n\",xgb_rs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Final results\n",
    "\n",
    "From the fine tuning performed above we have the following results:\n",
    "\n",
    "| Model             | Train  | Test   | Difference | Behaviour           |\n",
    "|-------------------|--------|--------|------------|---------------------|\n",
    "| <code style=\"background:yellow\">**MLP Regressor** | 0.9379 | 0.9491 | 0.0112     | Slightly Overfitted |\n",
    "| **XGBoost**       | 0.858  | 0.9741 | 0.1161     | Overfitted          |\n",
    "    \n",
    "Therefore, we will consider the MLP regressor as our final model, because it has the best results among all the models runned thoughout the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Root Mean Squared Error:  0.9379164195501649\n",
      "Test Root Mean Squared Error:  0.9490516506590705\n"
     ]
    }
   ],
   "source": [
    "final_model = MLPRegressor(random_state=0)\n",
    "final_model.set_params(**nn_rs.best_params_)\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "y_trainpred = final_model.predict(X_train)\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "print (\"Train Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_train, y_trainpred)))\n",
    "print (\"Test Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained throught the notebook, we have not been able to feed the model with all the information we wanted to, due to time constraint. Therefore, we expect that if we had been able to implement the NLP techniques needed, the scoring of the model would be much better. However, please note that the overfitting of the model is nearly 0, which is what we were seeking for: the generability of the model is high."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
